{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nfrom IPython.display import display\nimport h5py ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Path to your dataset folder..........\npath = '../input/101_ObjectCategories'\nos.chdir(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folders = os.listdir()\n# print(folders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making image square for efficient training....\n#For reference: https://stackoverflow.com/questions/44231209/resize-rectangular-image-to-square-keeping-ratio-and-fill-background-with-black/44231784\ndef make_square(image, min_size=img_size, fill_color=(0, 0, 0, 0)):\n    size = (min_size, min_size)\n    image.thumbnail(size, Image.ANTIALIAS)\n    background = Image.new('RGB', size, (255, 255, 255, 0))\n    background.paste(\n        image, (int((size[0] - image.size[0]) / 2), int((size[1] - image.size[1]) / 2))\n    )\n    new_img = np.array(background, dtype=np.uint8)/255\n    return new_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking number of images in dataset......\nnoOfImages = 0\nfor folder in range(len(folders)):\n  pathFolder = str(folders[folder]) + \"/\"\n  os.chdir(pathFolder)\n  folderImages = os.listdir()\n\n  for image in range(len(folderImages)):\n    noOfImages += 1\n    \n\n\n\n  os.chdir(\"..\")\n  \nprint(\"Number of Images\",noOfImages)\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Processing each image and converting to array....................\ndatasetImages = np.zeros((noOfImages,img_size,img_size,3)) #allocating memory for efficient storage, avoid using python list and then appending..............\ndatasetClasses = []\ncount = 0\n\nfor folder in range(len(folders)):\n  pathFolder = str(folders[folder]) + \"/\"\n  os.chdir(pathFolder)\n  folderImages = os.listdir()\n  \n  for image in range(len(folderImages)):\n    img = Image.open(folderImages[image])\n    imageArray = make_square(img)\n    datasetImages[count] = imageArray\n    datasetClasses.append(folder)\n    count += 1\n    \n  os.chdir(\"..\")\n\ndatasetClasses = np.array(datasetClasses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(datasetImages[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing directory to working directory in case of Kaggle, For others leave as it is.........\nos.chdir(\"..\")\nos.chdir(\"..\")\nos.chdir(\"working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking current directory..............\nprint(os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(datasetImages))\nprint(type(datasetClasses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing image array into HDF5 structure for faster and efficient storage.....\n#For reference: https://support.hdfgroup.org/HDF5/doc/H5.intro.html\n#             : https://realpython.com/storing-images-in-python/\ndef store_into_hdf5(imagesArray,labelsArray):\n  num_images = len(imagesArray)\n  file = h5py.File(\"imageDataset.h5\",\"w\")\n      # Create a dataset in the file\n  dataset = file.create_dataset(\n      \"images\", (len(imagesArray),img_size,img_size,3), h5py.h5t.STD_U8BE, data=imagesArray\n  )\n  meta_set = file.create_dataset(\n      \"meta\", (len(labelsArray),1) , h5py.h5t.STD_U8BE, data=labelsArray\n  )\n  file.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_into_hdf5( datasetImages, datasetClasses )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# free RAM memory when variable is used.........................\ndel datasetImages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del datasetClasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# incase you want to remove file from Kaggle\n# os.remove(\"imageDataset.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading image array but in compressed mode, you can see image size has been reduced..............\ndef read_many_hdf5():\n    \"\"\" Reads image from HDF5.\n        Parameters:\n        ---------------\n        num_images   number of images to read\n\n        Returns:\n        ----------\n        images      images array, (N, 32, 32, 3) to be stored\n        labels      associated meta data, int label (N, 1)\n    \"\"\"\n    images, labels = [], []\n\n    # Open the HDF5 file\n    file = h5py.File(\"imageDataset.h5\", \"r+\")\n\n    images = np.array(file[\"/images\"]).astype(\"uint8\")\n    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n\n    return images, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasetImages, datasetClasses = read_many_hdf5()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    datasetImages, datasetClasses, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nnum_classes = len(np.unique(datasetClasses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert class vectors to binary class matrices\n# For reference: https://stackoverflow.com/a/53430549\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten , BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For using TPU, incase using gpu don't run this cell...............\nimport tensorflow as tf\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tpu_strategy.scope(): # Remove this line incase you are not using TPU..............\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    #model.add(Dropout(0.3))\n    model.add(Dense(num_classes, activation = 'softmax')) #As number of nodes in last layer in softmax is number of classes, where each node is probability of classes\n    \n    model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Augmentation for deep network to identify images correctly..\n# For Reference: https://www.quora.com/What-is-data-augmentation-in-deep-learning\nfrom keras.preprocessing.image import ImageDataGenerator\n# performing data argumentation by training image generator\ndataAugmentaion = ImageDataGenerator(rotation_range = 30, zoom_range = 0.20, \nfill_mode = \"nearest\", shear_range = 0.20, horizontal_flip = True, \nwidth_shift_range = 0.1, height_shift_range = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training in batches, you can use fit() for smaller dataset training.......\n#For Refernce : https://datascience.stackexchange.com/a/34452\nmodel.fit_generator(dataAugmentaion.flow(X_train, y_train, batch_size = 32),\n validation_data = (X_test, y_test), steps_per_epoch = len(X_train) // 32,\n epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating performance of the model................\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}